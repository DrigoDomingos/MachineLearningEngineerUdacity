{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Projeto Final\n",
    "## Projeto: Melhorando a retenção de clientes na indústria de seguros\n",
    "\n",
    "O projeto “Melhorando a retenção de clientes na indústria de seguros” tem como objetivo analisar os dados históricos da carteira de clientes de uma seguradora a fim de encontrar padrões de comportamentos nos clientes que não renovaram suas apólices, com isto criar um modelo preditivo que aplicado as apólices que estão vigentes hoje, retornem a probabilidade de determinado cliente não renovar sua apólice ao final do contrato.\n",
    "\n",
    "Isto possibilitaria a seguradora manter uma régua de comunicação e interação diferenciada com os clientes com alta probabilidade de não renovar. Com esse cliente sentindo-se **“Único”** e isto possui um peso na decisão do cliente, espera-se uma melhorar no Índice de renovação das apólices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup Logging \n",
    "import logging\n",
    "import datetime\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Logging setup!\")\n",
    "\n",
    "# Setup Variables \n",
    "var_train_start = '02/2017'\n",
    "var_train_end   = '10/2017'\n",
    "var_valid       = '11/2017'\n",
    "var_pred        = '01/2018'\n",
    "\n",
    "print(\"Running the model with the following configurations:\")\n",
    "print(datetime.datetime.today())\n",
    "print(\"Start training: \",var_train_start)\n",
    "print(\"End training  : \",var_train_end)\n",
    "print(\"Validation    : \",var_valid)\n",
    "print(\"Prediction    : \",var_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "logger.info(\"Start loading Libraries\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "\n",
    "from plotly import figure_factory as FF\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot\n",
    "from plotly.graph_objs import Scatter, Figure, Layout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasql import sqldf\n",
    "import xgboost as xgb\n",
    "import qgrid\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logger.info(\"Finish loading Libraries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading data\n",
    "logger.info(\"Start reading Libraries\")\n",
    "insurance_data = pd.read_csv(\"../input/dataset_insurance.csv\",sep=';')\n",
    "logger.debug(\"insurance_data: {}\",insurance_data)\n",
    "\n",
    "logger.info(\"Finish reading Libraries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_notebook_mode(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data analysis\n",
    "logger.info(\"Start data exploration\")\n",
    "\n",
    "#Data analysis\n",
    "qgrid_widget = qgrid.show_grid(insurance_data,show_toolbar = True)\n",
    "qgrid_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dataset description\n",
    "insurance_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dtypes\n",
    "print(\"insurance_data data types: \")\n",
    "print(insurance_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Frequency outcome\n",
    "print(\"insurance_data 'Resultado' frequency: \")\n",
    "print(insurance_data['Resultado'].value_counts())\n",
    "\n",
    "logger.info(\"Finish data exploration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start visual exploration\")\n",
    "#Preparing data for plotting\n",
    "\n",
    "renovou_vis = sqldf(\"SELECT AnoMes, count(*) as IdCount_r  \\\n",
    "             FROM insurance_data \\\n",
    "             WHERE Resultado = 'Renovou' \\\n",
    "             group by AnoMes\")\n",
    "\n",
    "Nrenovou_vis = sqldf(\"SELECT AnoMes, count(*) as IdCount_Nr  \\\n",
    "             FROM insurance_data \\\n",
    "             WHERE Resultado = 'NaoRenovou' \\\n",
    "             group by AnoMes\")\n",
    "\n",
    "insurance_data_vis = (sqldf(\"SELECT a.AnoMes, (cast(IdCount_r as float)/(cast(IdCount_Nr as float) + cast(IdCount_r as float))) as IndiceRenovacao  \\\n",
    "             FROM renovou_vis a \\\n",
    "             INNER JOIN Nrenovou_vis b on a.AnoMes = b.AnoMes \\\n",
    "             WHERE a.AnoMes <> '01/2018'\"\n",
    "           ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "\n",
    "x = list(insurance_data_vis['AnoMes'].apply(str))# list(['01/2017', '02/2017', '03/2017', '04/2017', '05/2017', '06/2017', '07/2017', '08/2017', '09/2017', '10/2017', '11/2017', '12/2017', '01/2018'])\n",
    "y = list(insurance_data_vis.IndiceRenovacao)\n",
    "df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "data = [\n",
    "    go.Scatter(\n",
    "        x=df['x'], # assign x as the dataframe column 'x'\n",
    "        y=df['y']\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Índice Renovação 2017',\n",
    "    yaxis=(dict(title='Índice de Renovação (%)', range=[0,1])),   \n",
    "    xaxis=dict(title='Mes/Ano Vencimento Apólice')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# IPython notebook\n",
    "# py.iplot(fig, filename='pandas/line-plot-title')\n",
    "\n",
    "url = iplot(fig, filename='pandas/line-plot-title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Density plot\n",
    "insurance_data_vis = insurance_data[insurance_data.Resultado == 'NaoRenovou']\n",
    "insurance_data_vis = insurance_data_vis[['SaudeFinancCli','ExpSinistroCli','ExpSinistroCorr','IndFechCorr','ExpAss24','ExpCallCenterCli']]\n",
    "ax = insurance_data_vis.plot.density(title=\"Features Density [NaoRenovou]\")\n",
    "ax.set(xlabel=\"Values\", ylabel=\"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Density plot\n",
    "insurance_data_vis = insurance_data[insurance_data.Resultado == 'Renovou']\n",
    "insurance_data_vis = insurance_data_vis[['SaudeFinancCli','ExpSinistroCli','ExpSinistroCorr','IndFechCorr','ExpAss24','ExpCallCenterCli']]\n",
    "ax = insurance_data_vis.plot.density(title=\"Features Density [Renovou]\")\n",
    "ax.set(xlabel=\"Values\", ylabel=\"Density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pair PLot\n",
    "insurance_data_vis = insurance_data[['Resultado','SaudeFinancCli','ExpSinistroCli','ExpSinistroCorr','IndFechCorr','ExpAss24','ExpCallCenterCli']]\n",
    "g = sns.pairplot(insurance_data_vis, hue=\"Resultado\", palette=\"husl\")\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Cross values - [Renovou/NaoRenovou]', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Features correlation\n",
    "g = sns.FacetGrid(insurance_data, col='Resultado')\n",
    "g.map_dataframe(lambda data, color: sns.heatmap(insurance_data.corr(), linewidths=0, cmap=\"YlGnBu\"))\n",
    "g.fig.subplots_adjust(top=0.8)\n",
    "g.fig.suptitle('Correlation plot - [Renovou/NaoRenovou]', fontsize=16)\n",
    "g.fig.set_size_inches(11.7, 8.27)\n",
    "logger.info(\"Finish visual exploration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start data processing\")\n",
    "#Function to label Encoder and Normalization\n",
    "def dummyEncode(df):\n",
    "        columnsToEncode = df.select_dtypes(include=['category', 'object'])\n",
    "        columnsNumeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        \n",
    "        for feature in columnsToEncode:\n",
    "            if (feature != 'AnoMes' and feature != 'Resultado'): \n",
    "                try:\n",
    "                    df[feature] = le.fit_transform(df[feature])\n",
    "                    #df[feature] = scaler.fit_transform(df[[feature]]\n",
    "                except:\n",
    "                    print('Fail to encode: ' + feature)\n",
    "        return df\n",
    "    \n",
    "def MinMaxScale(df):\n",
    "        columnsNumeric = df.select_dtypes(include=['int64', 'float64'])\n",
    "        for feature in columnsNumeric:\n",
    "            if (feature != 'Resultado'):\n",
    "                try:\n",
    "                    scaler = MinMaxScaler()\n",
    "                    df[feature] = scaler.fit_transform(df[[feature]].apply(lambda x: round(x,3)))\n",
    "                except:\n",
    "                    print('Fail in Normalization '+ feature)  \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Savind unique ID of prediction\n",
    "pred_IdConta = insurance_data[(insurance_data.AnoMes == var_pred)]['IdConta']\n",
    "logger.debug(\"Unique ID of predictions: {}\", pred_IdConta)\n",
    "\n",
    "# Prediction original dataset - whitout transformation\n",
    "output_pred = insurance_data[(insurance_data.AnoMes == var_pred)]\n",
    "\n",
    "# Dropping Columns\n",
    "insurance_data['Resultado'] = insurance_data[['Resultado']].replace(['NaoRenovou', 'Renovou'], [0, 1]).fillna(0.0).astype(int)\n",
    "#insurance_data['Resultado'] = insurance_data['Resultado'].fillna(0.0).astype(int)\n",
    "\n",
    "insurance_data = pd.DataFrame(insurance_data.drop(['IdConta','Produto'],axis = 1))\n",
    "\n",
    "# Label Encoding\n",
    "insurance_data = pd.DataFrame(dummyEncode(insurance_data))\n",
    "\n",
    "# Normalization\n",
    "insurance_data = pd.DataFrame(MinMaxScale(insurance_data))\n",
    "\n",
    "\n",
    "# Data Split\n",
    "train = insurance_data[(insurance_data.AnoMes >= var_train_start) & (insurance_data.AnoMes <= var_train_end)]\n",
    "valid = insurance_data[(insurance_data.AnoMes == var_valid)]\n",
    "ori_pred = insurance_data[(insurance_data.AnoMes == var_pred)]\n",
    "\n",
    "x_train = train.drop(['Resultado','AnoMes'],axis = 1)\n",
    "y_train = train[['Resultado']]\n",
    "\n",
    "x_valid = valid.drop(['Resultado','AnoMes'],axis = 1)\n",
    "y_valid = valid[['Resultado']]\n",
    "\n",
    "x_ori_pred = ori_pred.drop(['Resultado','AnoMes'],axis = 1)\n",
    "\n",
    "# Sparse Matrix\n",
    "d_train = xgb.DMatrix(x_train, y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, y_valid)\n",
    "d_test = xgb.DMatrix(x_ori_pred)\n",
    "\n",
    "logger.info(\"Finish data processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start data training\")\n",
    "# Parameters\n",
    "xgb_params = {'eta': 0.3\n",
    "             ,'gamma': 0\n",
    "             ,'min_child_weight':1\n",
    "             ,'max_delta_step':0\n",
    "             ,'subsample':1\n",
    "             ,'colsample_bytree ':1\n",
    "             ,'colsample_bylevel':1\n",
    "             ,'lambda': 1\n",
    "             ,'alpha':1\n",
    "             ,'scale_pos_weight':1         \n",
    "             ,'max_depth': 6\n",
    "             ,'objective': 'binary:logistic'\n",
    "             ,'eval_metric': 'logloss'\n",
    "             ,'seed': 99\n",
    "             ,'silent': True}      \n",
    "# Model trainig\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "model = xgb.train(xgb_params \n",
    "                  ,d_train, 1000\n",
    "                  ,watchlist\n",
    "                  ,maximize=False\n",
    "                  ,verbose_eval=50\n",
    "                  ,early_stopping_rounds=10)\n",
    "logger.info(\"Finish data training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start data validation\")\n",
    "model_pred = model.predict(d_valid)\n",
    "cm=confusion_matrix(y_valid, model_pred.round()) \n",
    "ax= plt.subplot()\n",
    "sns.heatmap(pd.DataFrame(cm), linewidths=0, cmap=\"YlGnBu\",annot=True,ax = ax,fmt='g')\n",
    "# labels, title and ticks\n",
    "ax.figsize=(15,8)## Validação\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['NaoRenova', 'Renova']); ax.yaxis.set_ticklabels(['NaoRenova', 'Renova']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display stats metrics\n",
    "from pandas_ml import ConfusionMatrix\n",
    "cm = ConfusionMatrix(list(y_valid['Resultado']), list(model_pred.round()))\n",
    "print(\"Class statistics: \")\n",
    "cm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Finish data validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Start prediction\")\n",
    "#Savind the prediction output\n",
    "\n",
    "output_pred['prediction%'] = model.predict(d_test)\n",
    "output_pred['prediction']  = model.predict(d_test).round() \n",
    "display(output_pred.head())\n",
    "\n",
    "try:\n",
    "    output_pred.to_csv(\"../output/\" + 'output_predicted_' + var_pred.replace(\"/\",\"\") +'.csv', sep='|', encoding='utf-8',index=False)\n",
    "    print(\"File saved!\")\n",
    "except:\n",
    "    print(\"Failed to save the output\")    \n",
    "    \n",
    "logger.info(\"Finish prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting feature importance\n",
    "xgb.plot_importance(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
